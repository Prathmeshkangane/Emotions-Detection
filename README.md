# ğŸ­ Emotion Detection from Speech using Deep Learning

This project focuses on detecting human emotions from speech signals using an LSTM-based deep learning model. It leverages audio signal processing and machine learning techniques to classify emotional states such as **Happy**, **Sad**, **Angry**, **Fearful**, and **Neutral**.

---

## ğŸš€ Features

- ğŸ¤ **Real-Time Speech Emotion Recognition**  
- ğŸ§  **LSTM-based Deep Learning Model**
- ğŸ“Š **Waveform Visualization and Emotion Distribution Charts**
- âš¡ **Streamlit-based UI for Instant Interaction**
- ğŸ” **MFCC Feature Extraction using Librosa**
- ğŸ“ **Supports both real-time microphone input and pre-recorded files**

---

## ğŸ“Š Model Overview

- **Architecture**: LSTM
- **Input**: MFCC Features (20 coefficients)
- **Dataset**: RAVDESS + Custom Augmented Dataset
- **Accuracy**: High accuracy with well-separated emotion classes

---

## ğŸ› ï¸ Installation

git clone https://github.com/Prathmesh0001761/Emotion-detections-updated.git

cd Emotion-detections-updated

pip install -r requirements.txt

â–¶ï¸ Run the App

streamlit run app.py

ğŸ“Œ Dependencies

Python 3.8+

TensorFlow 2.x

Streamlit

Librosa

NumPy

Soundfile

Matplotlib

Install all dependencies using:

pip install -r requirements.txt

ğŸ’¡ Future Enhancements

ğŸ¯ Improve accuracy with attention mechanism

ğŸ™ï¸ Add support for longer conversations

ğŸ§ª Integrate with chatbot for emotion-aware responses
